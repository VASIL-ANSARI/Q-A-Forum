<p>The actual code you use will change the results here, and why the test comes to 0 as the result is a matter of speculation without that. </p>

<p>That said, micro benchmarks in JavaScript these days are subject to <a href="http://mrale.ph/blog/2012/12/15/microbenchmarks-fairy-tale.html" rel="nofollow">optimizations</a>. For example: </p>

<pre><code>function spiffy() {
    /* long bit of code that
       loops and loops and runs in 
       O(n!) time then finally */ 
    return result; 
}
</code></pre>

<p>Spiffy!</p>

<p>Let's say <code>spiffy()</code> deterministically always outputs the same result. The optimizer is allowed to effectively run this as: </p>

<pre><code>function spiffy() { 
    return 42; 
}
</code></pre>

<p>Which turns </p>

<pre><code>function someFunction (){
    var t0 = performance.now();
    var result = spiffy();
    var t1 = performance.now();
    Console.log(t1 - t0);
}
</code></pre>

<p>into a useless test result. </p>

<p>If you've got a bona-fide performance problem in your JavaScript app, I would profile it when it's running <a href="https://en.wikipedia.org/wiki/Boston_Molasses_Disaster" rel="nofollow">slower than molasses</a> and analyze the busiest portions of your code. And I don't mean micro benchmarks, but <a href="http://stackoverflow.com/questions/3255/big-o-how-do-you-calculate-approximate-it">examining run-time</a>, <a href="http://rads.stackoverflow.com/amzn/click/059651624X" rel="nofollow">look at the algorithm</a> you're using in that section and see if there might be a better one for your circumstances, and finally, ask someone else about the <em>actual code</em> in question, <em>in the same context</em> it's running in. </p>
