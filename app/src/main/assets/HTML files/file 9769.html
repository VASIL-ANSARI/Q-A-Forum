<p>Web::Scraper is useful for scraping.</p>

<pre><code>use strict;
use warnings;
use WWW::Mechanize;
use Web::Scraper;

my $mech = WWW::Mechanize-&gt;new;
$mech-&gt;env_proxy;
# If you want to login, do it with mechanize.

my $staff = scrape { process 'div.sometag li.tags a', 'links[]' =&gt; '@href' };
# pass mechanize to scraper as useragent.
$staff-&gt;user_agent($mech);

my $res = $staff-&gt;scrape( URI-&gt;new("http://example.com/") );
for my $link (@{$res-&gt;{links}}) {
    warn $link;
}
</code></pre>

<p>Sorry, I didn't test this code.</p>
