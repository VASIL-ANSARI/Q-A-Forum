<p>I had encountered this problem and browsed a lot of web pages. I summary two methods to solve this problem. </p>

<p>However, I think we should know why that happened. Python limits the number of recursive(default number is 1000). We can see this number with <code>print sys.getrecursionlimit()</code>. I guess that <strong>BeautifulSoup uses recursion to find child elements</strong>. When recursion is more than 1000 times, <code>RuntimeError: maximum recursion depth exceeded</code> will appear.</p>

<p><strong>First method:</strong> use <code>sys.setrecursionlimit()</code> set limited number of recursive. You obviously can set 1000000, but maybe cause <code>segmentation fault</code>.</p>

<p><strong>Second Method:</strong> use <code>try-except</code>. If appeared  <code>maximum recursion depth exceeded</code>, Our algorithm might have problems. Generally speaking, we can use loops instead of recursion. In your question, we could deal with HTML with <code>replace()</code> or regular expression in advance.</p>

<p>Finally, I give an example.</p>

<pre><code>from bs4 import BeautifulSoup
import sys   
#sys.setrecursionlimit(10000)

try:
    doc = ''.join(['&lt;br&gt;' for x in range(1000)])
    soup = BeautifulSoup(doc, 'html.parser')
    a = soup.find('br')
    for i in a:
        print i
except:
    print 'failed'
</code></pre>

<p>If removed the <code>#</code>, it could print <code>doc</code>.</p>

<p>Hoping to help you.</p>
