<p>In one of our projects where we employed Lucene for full text indexing &amp; search, we handled HTML files as follows:</p>

<ul>
<li>Stored the HTML document as is on disk (you can store in the DB as well).</li>
<li>Using <a href="http://jericho.htmlparser.net/docs/index.html" rel="nofollow">Jericho HTMLParser</a>'s  HTML->Text converter, we extracted the text, links etc., out of the HTML documents.</li>
<li>The lucene document has attributes that stored the metadata about the HTML file apart from the text content in the HTML in tokenized format.</li>
<li>Used StandardAnalyzer to keep certain tokens like email, website links as is during the tokenization process before indexing.</li>
<li>Upon searching the index, the hits returned contained the metadata of the HTML files that matched the criteria. So, we were able to identify the HTML content to be displayed for a given search result.</li>
</ul>

<p>HTH.</p>
