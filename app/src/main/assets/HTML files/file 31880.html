<p>First, your design is a bit silly, since you can do the same thing like this:</p>

<pre><code>process = subprocess.Popen(
                           ["python", "-h"],
                           bufsize=1,
                           stdout=sys.stdout,
                           stderr=sys.stderr
                           )
</code></pre>

<p>â¦ or, even better:</p>

<pre><code>process = subprocess.Popen(
                           ["python", "-h"],
                           bufsize=1
                           )
</code></pre>

<p>However, I'll assume that's just a toy example, and you might want to do something more useful.</p>

<hr>

<p>The main problem with your design is that it won't read anything from <code>stderr</code> until <code>stdout</code> is done.</p>

<p>Imagine you're driving an MP3 player that prints each track name to stdout, and logging info to stderr, and you want to play 10 songs. Do you really want to wait 30 minutes before displaying any of the logging to your users?</p>

<p>If that <em>is</em> acceptable, then you might as well just use <code>communicate</code>, which takes care of all of the headaches for you.</p>

<p>Plus, even if it's acceptable for your model, are you sure you can queue up that much unread data in the pipe without it blocking the child? On every platform?</p>

<p>Just breaking up the loop to alternate between the two won't help, because you could end up blocking on <code>stdout.readline()</code> for 5 minutes while <code>stderr</code> is piling up.</p>

<p>So that's why you need some way to read from both at once.</p>

<hr>

<p>How do you read from two pipes at once?</p>

<p>This is the same problem (but smaller) as handling 1000 network clients at once, and it has the same solutions: threading, or multiplexing (and the various hybrids, like doing green threads on top of a multiplexor and event loop, or using a threaded proactor, etc.).</p>

<p>The best sample code for the threaded version is <a href="http://hg.python.org/cpython/file/7f176a45211f/Lib/subprocess.py#l880" rel="nofollow"><code>communicate</code></a> from the 3.2+ source code. It's a little complicated, but if you want to handle all of the edge cases properly on both Windows and Unix there's really no avoiding a bit of complexity.</p>

<p>For multiplexing, you can use the <a href="http://docs.python.org/3/library/select.html" rel="nofollow"><code>select</code></a> module, but keep in mind that this only works on Unix (you can't <code>select</code> on pipes on Windows), and it's buggy without 3.2+ (or the <code>subprocess32</code> backport), and to really get all the edge cases right you need to add a signal handler to your <code>select</code>. Unless you really, really don't want to use threading, this is the harder answer.</p>

<p>But the <em>easy</em> answer is to use someone else's implementation. There are a dozen or more modules on PyPI specifically for async subprocesses. Alternatively, if you already have a good reason to write your app around an event loop, just about every modern event-loop-driven async networking library (including the stdlib's <a href="http://docs.python.org/dev/library/asyncio.html" rel="nofollow"><code>asyncio</code></a>) includes subprocess support out of the box, that works on both Unix and Windows.</p>

<hr>

<blockquote>
  <p>Is there a recommended approach for capturing the output of a process using python?</p>
</blockquote>

<p>It depends on who you're asking; a thousand Python developers might have a thousand different answersâ¦ or at least half a dozen. If you're asking what the core devs would recommend, I can take a guess:</p>

<p>If you don't need to capture it asynchronously, use <code>communicate</code> (but make sure to upgrade to at least 3.2 for important bug fixes). If you do need to capture it asynchronously, use <code>asyncio</code> (which requires 3.4).</p>
