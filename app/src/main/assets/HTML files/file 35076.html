<p>The best idea in this situation is probably to launch a dedicated process just for this stuff. Any other way and your objects are not guaranteed to be single across your deployment cluster.</p>

<p>If you are deploying using separate process workers you will have several different copies of your NLP data (one per process), and if you're deploying using cooperative threads (such as when using gunicorn gevent workers) then you have to make sure your code is thread-safe.</p>

<p>I would set up this as an external service running on a dedicated process, and have each client access this service using your choice of intra-process communication (sockets, HTTP, whatever).</p>

<p>For local development, testing purposes and ease of deployment you can always fall back to loading these objects into your projects settings.</p>
