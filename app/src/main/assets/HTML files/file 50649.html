<p>Scrapy works in an <a href="http://doc.scrapy.org/en/latest/topics/practices.html" rel="nofollow">asynchronous</a> kind, that is why your idea doesn't work. A working solution would be to save the 'request.url' or 'response.url' together with the scraped result in a freshly generated output.csv</p>

<p>For the 2nd part of your question, have you tried <a href="http://stackoverflow.com/questions/25521303/scrapy-another-method-to-avoid-a-lot-of-try-except">try &amp; except</a>:</p>

<pre><code>producto = Product()
try:
    producto = Product(BBB_link = response.xpath('//*[@id="container"]/div/div[1]/div[3]/table/tbody/tr[1]/td/h4[1]/a').extract()
except:
    producto = 'n/a'
</code></pre>
