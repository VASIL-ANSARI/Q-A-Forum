<p>Without more details, it's hard to give a detailed answer.  However, hopefully the following will help you frame the problem.</p>

<p>If your thread code is proper (e.g. you properly lock shared resources), you should not experience any bugs introduced by the change of hardware architecture.  Improper threading code can sometimes be masked by the specifics of how a specific platform handles things like CPU cache access/sharing.</p>

<p>You may experience a change in application performance per equivalent core due to differing approaches to memory and cache management in the single chip, multi core vs. multi chip alternatives.</p>

<p>Specifically if you are looking at hardware that has separate memory per CPU, I would assume that each thread is going to be locked to the CPU it starts on (otherwise, the system would have to incur significant overhead to move a thread's memory to memory dedicated to a different core).  That may reduce overall system efficiency depending on your specific situation.  However, separate memory per core also means that the different CPUs do not compete with each other for a given cache line (the 4 cores on each of the dual CPUs will still potentially compete for cache lines, but that is less contention than if 6 cores are competing for the same cache lines).</p>

<p>This type of cache line contention is called <em>False Sharing</em>.  I suggest the following read to understand if that may be an issue you are facing</p>

<p><a href="http://www.drdobbs.com/parallel/eliminate-false-sharing/217500206?pgno=3" rel="nofollow">http://www.drdobbs.com/parallel/eliminate-false-sharing/217500206?pgno=3</a></p>

<p>Bottom line is, application behavior should be stable (other than things that naturally depend on the details of thread scheduling) if you followed proper thread development practices, but performance could go either way depending on exactly what you are doing.</p>
