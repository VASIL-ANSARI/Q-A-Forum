<p>Yes, it's possible, though you will have to use a slightly different API.</p>

<p>The example you linked to uses <code>AVCaptureMetadataOutput</code>, which makes integration easy in the AVFoundation framework, especially for real-time video.</p>

<p>In the case of a single still image, it's easier to use a <a href="https://developer.apple.com/library/ios/documentation/CoreImage/Reference/CIDetector_Ref/" rel="nofollow"><code>CIDetector</code></a> with the appropriate type (<code>CIDetectorTypeQRCode</code>).</p>

<p>A full example of the use of <code>CIDetector</code> can be found in <a href="https://developer.apple.com/library/ios/documentation/GraphicsImaging/Conceptual/CoreImaging/ci_detect_faces/ci_detect_faces.html" rel="nofollow">Detecting Faces in an Image</a> in the Core Image Programming Guide. You'll just have to switch the type you want.</p>
