<p>Although I don't have much experience using HDF5 files, I'll suggest three Python libraries that might get you going in a  better direction</p>

<p><a href="http://www.h5py.org/" rel="nofollow">H5py</a> is a Python library specifically built for encoding and decoding files to and from binary formats.  I'm not claiming that it is better than Pandas HDFstore (I've found Pandas to be pretty awesome with handling sizable amounts of data 2.2M x 24) but it might do the trick.</p>

<p><a href="http://www.pytables.org/moin" rel="nofollow">PyTables</a> has been mentioned a few times in memory management conversations.  I have no experience with this library but I have seen it in discussions dealing with <a href="http://stackoverflow.com/questions/22998859/hdfstore-with-string-columns-gives-issues">memory/HDf5 problems</a>.</p>

<p><a href="https://docs.python.org/2.7/library/mmap.html" rel="nofollow">mmap</a> is a library used for memory mapping (The process of moving data from the disk, into memory for manipulating without the use of binary formatting).  If you guessed that I have no experience using this library, then you would be a winner.  </p>

<p>Again, I can't talk much from experience here, but I think these three routes might get you on you way of better utilizing your memory with Python when dealing with large data sets.</p>
