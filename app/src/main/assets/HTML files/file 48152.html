<p>The problem is that <code>LinearRegressionWithSGD</code> uses stochastic gradient descent (SGD) to optimize the weight vector of your linear model. SGD is really sensitive to the provided <code>stepSize</code> which is used to update the intermediate solution.</p>

<p>What SGD does is to calculate the gradient <code>g</code> of the cost function given a sample of the input points and the current weights <code>w</code>. In order to update the weights <code>w</code> you go for a certain distance in the opposite direction of <code>g</code>. The distance is your step size <code>s</code>.</p>

<pre><code>w(i+1) = w(i) - s * g   
</code></pre>

<p>Since you're not providing an explicit step size value, MLlib assumes <code>stepSize = 1</code>. This seems to not work for your use case. I'd recommend you to try different step sizes, usually lower values, to see how <code>LinearRegressionWithSGD</code> behaves:</p>

<pre class="lang-scala prettyprint-override"><code>LinearRegressionWithSGD.train(parsedData, numIterartions = 10, stepSize = 0.001) 
</code></pre>
