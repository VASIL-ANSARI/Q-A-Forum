<p>I found the output files of blast. It seems that they stay in the nodes where blast is executed. So after I put them back to hdfs, I could access them under the directory <code>/user/yarn</code>.
What I did is add the following code to <code>map.py</code>:</p>

<pre><code>command = 'hadoop fs -put %s' % output_file
cmd = Popen(command, stdin=PIPE, stdout=PIPE, shell=True)
</code></pre>

<p>And I also modified the output path as</p>

<pre><code>output_file = name
</code></pre>

<p>instead of using </p>

<pre><code>output_file = join(current_path, 'tmp_output', name)
</code></pre>

<p>[Update on 3/3]
But putting files under user yarn directory is not good, because normal user has no permission to edit the file under the directory. I recommend putting files into <code>/tmp/blast_tmp</code> by changing command to </p>

<pre><code>command = 'hadoop fs -put %s /tmp/blast_tmp' % output_file
</code></pre>

<p>Before that, the directory <code>/tmp/blast_tmp</code> should be created with</p>

<pre><code>% hadoop fs -mkdir /tmp/blast_tmp
</code></pre>

<p>and change the permission of the directory by</p>

<pre><code>% hadoop fs -chmod 777 /tmp/blast_tmp
</code></pre>

<p>in this case, both the user yarn and you can access the directory.</p>
