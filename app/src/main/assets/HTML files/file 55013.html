<p>Before answering which is better, here is a quick reminder of the algorithm:</p>

<ol>
<li>"Choose" the number of clusters <strong>K</strong></li>
<li>Initiate your <strong>first centroids</strong></li>
<li>For each point, find the <strong>closest centroid</strong>
according to a distance function <strong>D</strong></li>
<li>When all points are attributed to a cluster, calculate the <strong>barycenter</strong> of the cluster which become its new centroid</li>
<li>Repeat step 3. and step 4. until <strong>convergence</strong></li>
</ol>

<p>As stressed previously, the algorithm depends on various parameters:</p>

<ul>
<li>The number of clusters</li>
<li>Your initial centroid positions </li>
<li>A distance function to calculate distance between any point and centroid</li>
<li>A function to calculate the barycenter of each new cluster</li>
<li>A convergence metric</li>
<li>...</li>
</ul>

<p>If none of the above is familiar to you, and you want to understand the role of each parameter, I would recommend to re-implement it on low-dimensional data-sets. Moreover, the implemented Python libraries might not match your specific requirements - even though they provide good tuning possibilities.</p>

<p>If your point is to use it quickly with a big-picture understanding, you can use existing implementation - scikit-learn would be a good choice.</p>
