<p>As we discussed in comments, you can use <code>try/except</code> to avoid crashing while looping over (I see that you have changed you original code after this suggestion)</p>

<p>Then you can specify longer timeout in seconds, when using <code>urlopen</code> (see <a href="https://docs.python.org/2.7/library/urllib2.html#urllib2.urlopen" rel="nofollow">documentation</a>).</p>

<p>Additionally, inside your <code>for</code> loop, you can add another loop that will try to retrieve the data certain number of times or break as soon as <code>urlopen</code> gets what you need. Code below is based on <a href="http://stackoverflow.com/a/9446851/4241180">this answer</a>:</p>

<pre><code># number of attempt urlopen tries to open your url
attempts = 10

for _ in range(attempts):
    try:
        # you can use timeout argument for urlopen
        html = urllib2.urlopen(req, timeout=timeout).read()
        # urlopen successfully get the data
        break
    # urlopen fails to retrieve data
    except urllib2.URLError as err:
        print("Oops! urlopen failed")
# all attempts failed
else:
    print("Oops! All attempts failed")
# now use your html variable here
# ...
</code></pre>

<p>P.S. For those who downvoted: OP has changed his question/code after discussion in comments. This answer is a follow-up of that discussion, so please take the context into account.</p>
