<p>I think the best thing to do in this situation is translate the computers' strengths to an preliminary ELO rating.</p>

<p>I take my example from Chess and internet chess servers like <a href="http://freechess.org" rel="nofollow">FICS</a>.   When a computer plays, it's treated just like a human opponent - it gets a preliminary rating and is later rated based on whether it wins or loses against human and computer opponents.</p>

<p>You might have a bootstrapping problem, though, if you don't have enough players in that strong computers might not be able to get a decent rating because all the other players are weak.  In this case, you could simply map your 1-10 on the range of MIN_RATING- MAX_RATING.  MAX_RATING is not actually the max rating and MIN_RATING probably shouldn't be 0. ELO is a relative ranking system, the absolute numbers mean nothing, so you might choose them according to your player base.   In chess, the higher rating is around 27-2800 for Grandmasters and the lowest are around the 400s newbies that stick around but don't improve.</p>

<p>The main point here is that if you give them a preliminary rating, over time they will move towards their 'true rating' because they will play games against players and move accordingly.</p>

<p><em><strong>EDIT</em></strong></p>

<p>Why not just scale the weight constant based on the team differential? How about something like this:</p>

<pre><code>K*(F(9-abs(s1-s2))) 
</code></pre>

<p>where F(x) is a <a href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="nofollow">sigmoid function</a> or even just a linear function [0...9]->[1...0}.  This means a team with equal ratings gets the full constant and teams with bigger differences scale down to zero or whatever you choose.</p>

<p>I don't know if I agree that this calculation is the best way to approach this problem.  The statistics of ELO might not apply if you use it this way, but I don't have a better suggestion without doing more research.</p>
