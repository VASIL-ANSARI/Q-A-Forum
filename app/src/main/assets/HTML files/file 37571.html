<p>Since you can have more than one link in each "news post body", your one-at-a-time iteration won't work.</p>

<p>I would try to group them together under the "date of the news post" node, and then loop for a while. (It's unfortunate that your target document doesn't containerize the news posts :)</p>

<p>The cool thing about the Scrapy Selector is that you can call <code>xpath</code> on the results of an <code>xpath</code> call. Check it:</p>

<pre><code>#get all interesting date paragraphs
date = sel.xpath('//*/p[@class="date"]')

for eacDate in date:
    #eacDate is a paragraph node
    #extract all of the paragraphs after this one at the same level in the DOM,
    #then loop until you find a date paragraph, since that marks the start of the next section
    urls = []
    next_paragraphs = eacDate.xpath("following-sibling::p")
    for p in next_paragraphs:
        if p.xpath("@class").extract() == [u'date']:
            break
        urls.extend(p.xpath("a/@href").extract())
    print urls
</code></pre>

<p>You might want to read up on XPath Axes: <a href="http://www.w3schools.com/xpath/xpath_axes.asp" rel="nofollow">http://www.w3schools.com/xpath/xpath_axes.asp</a></p>
