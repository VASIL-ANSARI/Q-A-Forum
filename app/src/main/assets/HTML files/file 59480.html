<blockquote>
  <p>Will migrating my data from localized JSON files to MariaDB 10.1 be a
  best practice move? Is that the scalable alternative for the future?
  What should my stack look like to improve speed and improve search
  capabilities?</p>
</blockquote>

<p>Yes. The whole purpose of a database is to make the storageâand usageâof data like this easier in the long run.</p>

<p>Each time you load a JSON file in PHP, PHP has to parse the data and I highly doubt 200,000 listings that consist of 8GB of data will ever work well as a file loaded into PHP memory from the file system. PHP will most likely die (aka: throw up an error) just when you attempt to load the file to begin with. Sorting and manipulating that data in PHP in that low-level state is even less efficient.</p>

<p>Storing that JSON data in a database of some kindâMariaDB, MySQL, MongoDB, etcâ¦âis the only practical and best practice way to handle something like this.</p>

<p>The main reason anyone would repeatedly load a local JSON file into PHP would be for small tests and development ideas. On a practical level, itâs inefficient but when you are in an early stage of development and donât feel like dealing with creating a process to import a large JSON file like that into an actual database a small sample file of data can be useful from your developerâs perspective to hash out basic concepts and idea.</p>

<p>But there is utterly no âbest practiceâ that would ever state a file being read from a filesystem is a âbest practiceâ; itâs honestly a very bad idea.</p>
