<p>You could try something like this:</p>

<pre><code>with pm.Model() as model:
    p = np.array([0.5, 0.5])
    model_index = pm.Categorical('model_index', p=p)
    model0 # define one model here
    model1 # define the other model here
    m = pm.switch(model_index, model0, model1)
    # pass M to a prior or likelihood, for example
    y = pm.SomeDistribution('y', m, observed=data)

    step0 = pm.ElemwiseCategorical(vars=[model_index], values=[0,1])
    step1 = pm.NUTS()
    trace = pm.sample(5000, step=[step0, step1], start=start)
</code></pre>

<p>Then you compute the Bayes factors as: (add burnin if necessary)</p>

<pre><code>pm.traceplot(trace);
pM1 = trace['model_index'].mean()
pM0 = 1 - pM1
pM0, pM1, (pM0/pM1)*(p[1]/p[0])
</code></pre>

<p>You may also want to check how yo use Information Criteria to compare models, see an example <a href="https://github.com/pymc-devs/pymc3/blob/6bbb7911787fa664373e88ae9bd0def2e5b4f7ed/pymc3/examples/notebooks/Model%20Comparison.ipynb" rel="nofollow">here</a></p>
