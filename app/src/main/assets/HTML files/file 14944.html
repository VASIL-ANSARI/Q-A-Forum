<p>The primary point of the HAR format is to have a standard HTTP tracing format that many tools can use and analyze. In other words, it's original intent was and primarily is, for performance analysis, not "archiving" webpages per se.</p>

<p>If you fetch a page with <code>wget</code>, you're missing 99% of all the performance data. To capture the necessary data you really need a browser to execute the requests, fetch all the associated resources, save all the timers, etc. This will enable you to build the waterfall charts, etc. </p>

<p>If you need to capture this data on the server, then you can use pcap to capture the TCP trace and then <a href="http://pcapperf.appspot.com/">convert that to HAR</a>, although you still need a client which will actually parse the HTML and request all the sub-resources (pcap is just listening in the background). Alternatively, you can route your browser <a href="http://www.softwareishard.com/blog/har-adopters/">through a proxy</a> and let it spit out a HAR file for you.</p>

<p>Last but not least, you can just drive the browser through its debug interface and export the HAR file that way. Java example for driving Firefox: <a href="https://github.com/Filirom1/browsermob-page-perf">https://github.com/Filirom1/browsermob-page-perf</a></p>
