<p>From my point of view, it depends ...</p>

<p>As you may know, there are many profiling modes. For CPU/time profiling, trere are Sampling and Instrumentation.</p>

<p>Sample profiling is more âstatisticalâ profiling. The accuracy of the results is dependant on number of times the code executes during the profiling session. At regular intervals the Profiler takes a snapshot of the call stack of each thread executing on the target the process(es). If a Method has a huge number of samples, it can be because of many execution or long method execution. It is very lightweight and has minimal performance impact on the system, and is easy to use.</p>

<p>This instrumentation involves inserting probes into the target code at the start and end of each function being instrumented, so that the entry into and exit from every function call can be tracked. In a profiling session, the exact number of times a function is called and how long it takes to execute can be exactly measured. However, capturing this detail comes at a cost. There is a fairly significant processing overhead being introduced on every function call (usually at least 10% and can easily be 100% or more, but is more or less dependent on the size of the functions being profiled). The increase in code size and execution of additional code in the profiler can also cause some adverse CPU caching effects.</p>

<p>The last important thing to understand is that Profiling can be view as scientific approach because you should measure your code in a real conditions (or real use cases) to find out exactly where the bottlenecks are and fix them knowing it will improve the performance.</p>
