<p>If somebody really sends UTF-7, you will cause the client to decode it incorrectly.  But it's quite rare; most sites send UTF-8 if they use Unicode at all.  For the sample content you posted, it's pure ASCII, so it's valid both UTF-7 and UTF-8.  (UTF-7 assigns special semantics to + and - so for a message which contains sequences of these characters, even ASCII is not safe.  That is, UTF-7 incorrectly labeled as US-ASCII or vice versa will decode incorrectly.)</p>

<p>Assigning Quoted-Printable to stuff which really isn't is similarly haphazard; any equals sign in the message has special meaning in QP.  I think you should just leave it.</p>

<p>The proper solution is to really recode the message body, i.e. translate from UTF-7 to UTF-8 (and possibly wrap it in quoted-printable), then assign the correct content-type header; or, convince whatever is sending these messages to stick to plain old US-ASCII or switch to UTF-8.  (Or, find out how to teach Java to handle UTF-7 encoding; but that's outside my competence.)</p>

<p>See also <a href="http://en.wikipedia.org/wiki/UTF-7" rel="nofollow">http://en.wikipedia.org/wiki/UTF-7</a></p>

<hr>

<p>Basic RFC822 email was purely 7-bit.  In order to enable rich content and different character sets, <a href="http://en.wikipedia.org/wiki/MIME" rel="nofollow">MIME</a> was developed in the early 1990s.  Central to your question are two MIME headers, <code>Content-Type:</code> and <code>Content-Transfer-Encoding:</code>.  These are both used to identify the type of a MIME part, but they are distinct concepts.  The <code>Content-Type</code> describes what the data is (<code>text/html</code>, <code>audio/midi</code>, <code>application/octet-stream</code> for untyped binary data, etc).  The <code>Content-Transfer-Encoding:</code> indicates how it has been encoded for transmission over email (or another MIME conduit).</p>

<p><code>Content-Transfer-Encoding:</code> basically defines two encodings and three unencoded types.  CTE: <code>7bit</code> indicates that the data, by itself, is suitable for transmission over a 7-bit channel (there is also a line length restriction); <code>8bit</code> is not, and will need to be re-encoded if the channel cannot accommodate 8-bit data.  Similarly, <code>binary</code> is also 8-bit but in addition has no guarantee on line length (i.e. it may contain lines longer than approx 1,000 characters).  So to transmit <code>binary</code> or <code>8-bit</code> data across a 7-bit channel, you need to recode the content as <code>base64</code> or <code>quoted-printable</code>.  Both of these encodings substitute 8-bit characters with 7-bit sequences; the recipient is expected to perform the reverse substitution in order to decode and extract the data.</p>

<p>Once the extraction happens, the data is basically ready for use at the recipient end.  However, for text types, there is also the matter of character set encoding.  Many character sets are simply 7-bit or 8-bit, and so a byte in the stream corresponds to a character.  But multibyte character sets do not behave like this, and so they, too, need to be encoded somehow.  But this is distinct from the MIME 7bit/8bit thing described above.  A character encoding tells you how the byte stream encodes multi-byte characters.</p>

<p><a href="http://en.wikipedia.org/wiki/Utf-8" rel="nofollow">UTF-8</a> encodes a multibyte character as a sequence of 8-bit characters (while conveniently 7-bit characters are identical to the US-ASCII 7-bit encoding).  The encoding has some nice properties which you can read about in Wikipedia.</p>

<p>UTF-7 was never formally accepted as an official Unicode encoding, and is not in widespread use.  It is not entirely compatible with US-ASCII, because the <code>+</code> and <code>-</code> characters are used to encode multibyte character sequences.</p>

<p>If you wish to decode UTF-7 and your language does not support the encoding, you will have to write your own decoder.  The alternative is not to decode the encoding, and leave it to the downstream consumer to decode.  Take care to somehow relay the character encoding to the downstream in this case.  However, because UTF-7 is not widely supported, I would recommend recoding to UTF-8, which is widely supported and understood (and also, as mentioned, transparently compatible with US-ASCII if no multibyte characters are present).</p>

<p>So, just to summarize; if you change the headers, you also have to change the encoding.  If you are lucky (and your example is representative) the text doesn't contain any actual encoded UTF-7 multibyte characters, in which case you can safely relabel it as US-ASCII.  If it does contain <code>+</code> or <code>-</code> characters, they are part of UTF-7 sequences which need to be decoded (though again, you could be lucky, and the sequences are just the UTF-7 escapes which encode a literal plus or minus sign).</p>
