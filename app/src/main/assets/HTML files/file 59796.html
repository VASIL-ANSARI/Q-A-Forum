<h2>1) External library</h2>

<p>If you're willing to lean on external libraries (and time to execute is more important than the one-off time cost to install), you might be able to gain some speed by loading each file into a simple Pandas DataFrame and performing the keyword search as a vector operation. To get the matching tweets, you would do something like:</p>

<pre><code>import pandas as pd
dataframe_from_text = pd.read_csv("/path/to/file.txt")
matched_tweets_index =  dataframe_from_text.str.match("keyword_a|keyword_b")
dataframe_from_text[matched_tweets_index] # Uses the boolean search above to filter the full dataframe
# You'd then have a mini dataframe of matching tweets in `dataframe_from_text`. 
# You could loop through these to save them out to a file using the `.to_dict(orient="records")` format.
</code></pre>

<p>Dataframe operations within Pandas can be really quick so might be worth investigating.</p>

<h2>2) Group your regex</h2>

<p>Looks like you're not logging which keyword you matched against. If this is true, you could group your keywords into a single regex query like so:</p>

<pre><code>for line in f:
    keywords_combined = "|".join(keywords)
    if re.search(keywords_combined, line, re.IGNORECASE):
        db.write(line)
</code></pre>

<p>I've not tested this but by reducing the number of loops per line, that could trim some time off.</p>
