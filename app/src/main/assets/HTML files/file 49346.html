<p>By default, the logstash-input-jdbc plugin will run your SELECT statement once and then quit. You can change this behavior by adding a <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html#_usage" rel="nofollow"><code>schedule</code> parameter</a> with a cron expression to your configuration, like this:</p>

<pre><code>input {
 jdbc {
   jdbc_driver_library =&gt; "C:/logstash/lib/mysql-connector-java-5.1.37-bin.jar"
   jdbc_driver_class =&gt; "com.mysql.jdbc.Driver"
   jdbc_connection_string =&gt; "jdbc:mysql://127.0.0.1:3306/test"
   jdbc_user =&gt; "root"
   jdbc_password =&gt; ""
   statement =&gt; "SELECT * FROM transport.audit"
   schedule =&gt; "* * * * *"               &lt;----- add this line
   jdbc_paging_enabled =&gt; "true"
   jdbc_page_size =&gt; "50000"
 }
}
</code></pre>

<p>The result is that the SELECT statement will now run every minute.</p>

<p>If you had a date field in your MySQL table (but it doesn't seem the case), you could also use the pre-defined <code>sql_last_start</code> parameter in order to not re-index all records on every run. That parameter can be used in your query like this:</p>

<pre><code>   statement =&gt; "SELECT * FROM transport.audit WHERE your_date_field &gt;= :sql_last_start"
</code></pre>
